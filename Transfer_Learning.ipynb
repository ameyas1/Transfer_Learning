{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "068c5ea2-cf5f-4cc4-a600-cc2eb385cd17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11755
        }
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "\n",
        "  \n",
        "pre_trained_model.summary()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-09 12:54:24--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.139.128, 2607:f8b0:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.139.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  90.6MB/s    in 0.9s    \n",
            "\n",
            "2019-06-09 12:54:25 (90.6 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPp3RTkP_Ar3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in pre_trained_model.layers[:-43]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvB7-AxP8euP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5392
        },
        "outputId": "47dd81ff-5ff4-48cc-9308-9b5bae318f9c"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fb77fc2a150>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7319bd790>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb796871c10>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb78df90e50>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb73133c050>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb73133c4d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7313559d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7312dfed0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb731278210>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb73128e590>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fb731205790>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7312057d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb731217690>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7312b9a10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb73119e490>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb73119e450>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb73112dc10>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fb731121f10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730f5df50>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730ef2290>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730f08610>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb73103ec10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730e77810>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb73104de90>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730e8cf90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7310612d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730e9f0d0>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7fb730d9fc50>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb731121e10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730fdb4d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730dbbf10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730d9fb50>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb73108af50>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730fdb490>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730e19350>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730ca8e90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7310c8190>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730f6bc50>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730da7950>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730d33e50>, False)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb730cbb690>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730b02210>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730b02190>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730b12950>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730c00d90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730a8a9d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730c5b3d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730a8a990>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730bec990>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730a33050>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7fb7308ef510>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730cbbf10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730be3a10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7309ab1d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730944e10>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730ccd990>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730be39d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb7309ab150>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730935950>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730c25490>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730b8a090>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7309bb910>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb731b52090>, False)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb731b39cd0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7306a5dd0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730700290>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730711850>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb77f3b1210>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb73068b950>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb77f3b07d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb73068b910>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb77f3afc90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730635050>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7fb73052fa10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb731b25d90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7307e2890>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7305cbe90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb73052fa50>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb77f3b2290>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb7307e2850>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb7305a8350>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730542cd0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb731b4e790>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730775fd0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7305b7910>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb73051cb50>, False)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb7304ce5d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730413dd0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb7303ef590>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7303fe9d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730375ad0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730375a90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb73039b110>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7304ceed0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730310350>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb7304df910>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb730310310>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb73043b490>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730322a90>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fb730298c90>, False)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb730298b90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72fff84d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72fff8490>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb730009c10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72ff80e10>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ff95610>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72ff2b490>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7301bcb10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72ff20590>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb7301bcad0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ff20550>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7301e1310>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72feb3cd0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730150410>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72fe29ed0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb7301503d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72fe3f2d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7300e5b50>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72fe54550>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7fb72fd51f90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb730298bd0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb7300dad50>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72fdc7650>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72fd51e90>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb7301a5890>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb73006b550>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72fdc7610>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72fcbefd0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb73022ce90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb7300823d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72fddae10>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72fcfa1d0>, False)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72fc6ea50>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f9a6ed0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72fa0c950>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72fa4f410>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f9d88d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f9d8890>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f968d50>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72fc0c710>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f91de10>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72fc0c6d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f8f6490>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72fc1ce90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f90b890>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72fb90fd0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f87f990>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72fb25490>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f87f950>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72fb39710>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f826110>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7fb72f725a50>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72fc6ed90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72fab0810>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f7c4ed0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f725a90>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72fc7fd50>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72fab07d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f820550>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f738d10>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72fc59c10>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72fac1bd0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f7b0950>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f710b90>, False)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72f6c3610>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f48ecd0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f49fe90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f436350>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f3b2450>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f3b2410>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f3c3b90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f605e10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f339d90>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f65d5d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f34a590>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f5f0a10>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f35e410>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f568b10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f2d6510>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f568ad0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f2d64d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f590150>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f267c50>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7fb72f17d5d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f6c3fd0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f507390>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f25ee50>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f17d610>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f6d5950>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f507350>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f1f1650>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f18c890>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f62d4d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f51cad0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f2074d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f0e9710>, False)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72f0bee90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72eee4710>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72eee46d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72ee79e50>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72edecfd0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ee03450>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72ee196d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72f0a0e90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72ed8d7d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f032290>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ed8d790>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f048550>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72ed9ff10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72efbf650>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72ecd0d10>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72efbf610>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ec83f90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72efd0d90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72ecac3d0>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7fb72eb76dd0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72fc6ef10>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72ef48f90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72ec32890>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72ebd29d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72f11aa90>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ef5c390>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ec32850>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ebe3850>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72f11a4d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72eef3610>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72ec45fd0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72eb46c90>, False)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72eb5dd90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e9b9e90>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ea15510>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e9a6910>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e99fa10>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e99f9d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e945090>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72eb5dcd0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e8e1dd0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72eae3b10>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e8bf5d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72eaee190>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e8ce9d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72ea76910>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e843ad0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72ea768d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e843a90>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72eaa4050>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e7ec110>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fb72e7e4350>, False)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72e7e4390>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e52ccd0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e4b9ad0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e540190>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e6fd310>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e4cc910>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e6fd2d0>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e4cc8d0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e70dad0>, False)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e4750d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e684cd0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e623450>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e40ee90>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e373a10>, False)\n",
            "(<tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7fb72e321590>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e7e4690>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e695e90>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e623410>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e3e9510>, False)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e3739d0>, False)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e3112d0>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e775650>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e62b350>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e5abb90>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e3f9910>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e39c210>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e282e10>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e6e99d0>, True)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72e52cd90>, True)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72e2b6dd0>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e29b6d0>, True)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72e252dd0>, True)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72dff8f10>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e00ab10>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72df66690>, True)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e1b3f90>, True)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72df99490>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e1c5390>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72df99450>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e1dc650>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72df25c10>, True)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e150750>, True)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e0d9fd0>, True)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72df1ae10>, True)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72de3b590>, True)\n",
            "(<tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7fb72ddc3c50>, True)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72e23e590>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e150710>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e06e490>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72dead610>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72de3b550>, True)\n",
            "(<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fb72ddd66d0>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72e22d550>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e15ee90>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e084710>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72dec4490>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72de4ecd0>, True)\n",
            "(<tensorflow.python.keras.layers.normalization.BatchNormalizationV1 object at 0x7fb72dd6b0d0>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72e21c110>, True)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72dff8810>, True)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72ddc3ed0>, True)\n",
            "(<tensorflow.python.keras.layers.core.Activation object at 0x7fb72dd60cd0>, True)\n",
            "(<tensorflow.python.keras.layers.merge.Concatenate object at 0x7fb72dd60e90>, True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TkmnoKwcTeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77eceafd-cd38-459f-ec8b-faa0249ec4cc"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed10')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 3, 3, 2048))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c4bfbb0d-1fca-4151-b276-b32d3b41d90c"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(4096, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)  \n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(2048, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)  \n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = Adam(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "d5347367-7c01-46e8-9a31-82d06798f1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 80,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 250,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 100,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-09 12:54:38--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.31.128, 2607:f8b0:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.31.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_   6%[>                   ]   4.01M  15.8MB/s               \r        /tmp/cats_a  61%[===========>        ]  40.01M  82.5MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M   109MB/s    in 0.6s    \n",
            "\n",
            "2019-06-09 12:54:39 (109 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "57fca4d8-d31d-4176-e776-ad68cbaf07e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1022
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 50,\n",
        "            epochs = 18,\n",
        "            validation_steps = 20,\n",
        "            verbose = 2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/18\n",
            "10/10 [==============================] - 7s 672ms/step - loss: 0.3226 - acc: 0.8470\n",
            " - 24s - loss: 0.8755 - acc: 0.5630 - val_loss: 0.3226 - val_acc: 0.8470\n",
            "Epoch 2/18\n",
            "10/10 [==============================] - 5s 540ms/step - loss: 0.2885 - acc: 0.9290\n",
            " - 20s - loss: 0.5609 - acc: 0.6970 - val_loss: 0.2885 - val_acc: 0.9290\n",
            "Epoch 3/18\n",
            "10/10 [==============================] - 5s 532ms/step - loss: 0.5358 - acc: 0.9200\n",
            " - 19s - loss: 0.4683 - acc: 0.7805 - val_loss: 0.5358 - val_acc: 0.9200\n",
            "Epoch 4/18\n",
            "10/10 [==============================] - 5s 541ms/step - loss: 0.3377 - acc: 0.9420\n",
            " - 19s - loss: 0.3899 - acc: 0.8135 - val_loss: 0.3377 - val_acc: 0.9420\n",
            "Epoch 5/18\n",
            "10/10 [==============================] - 5s 540ms/step - loss: 0.2879 - acc: 0.9480\n",
            " - 19s - loss: 0.3469 - acc: 0.8410 - val_loss: 0.2879 - val_acc: 0.9480\n",
            "Epoch 6/18\n",
            "10/10 [==============================] - 5s 531ms/step - loss: 0.3662 - acc: 0.9400\n",
            " - 19s - loss: 0.3272 - acc: 0.8490 - val_loss: 0.3662 - val_acc: 0.9400\n",
            "Epoch 7/18\n",
            "10/10 [==============================] - 5s 534ms/step - loss: 0.2655 - acc: 0.9530\n",
            " - 19s - loss: 0.2986 - acc: 0.8635 - val_loss: 0.2655 - val_acc: 0.9530\n",
            "Epoch 8/18\n",
            "10/10 [==============================] - 5s 533ms/step - loss: 0.3513 - acc: 0.9380\n",
            " - 19s - loss: 0.3308 - acc: 0.8590 - val_loss: 0.3513 - val_acc: 0.9380\n",
            "Epoch 9/18\n",
            "10/10 [==============================] - 5s 539ms/step - loss: 0.3839 - acc: 0.9420\n",
            " - 20s - loss: 0.3191 - acc: 0.8545 - val_loss: 0.3839 - val_acc: 0.9420\n",
            "Epoch 10/18\n",
            "10/10 [==============================] - 5s 541ms/step - loss: 0.3801 - acc: 0.9460\n",
            " - 20s - loss: 0.2844 - acc: 0.8695 - val_loss: 0.3801 - val_acc: 0.9460\n",
            "Epoch 11/18\n",
            "10/10 [==============================] - 5s 544ms/step - loss: 0.3911 - acc: 0.9430\n",
            " - 20s - loss: 0.2748 - acc: 0.8800 - val_loss: 0.3911 - val_acc: 0.9430\n",
            "Epoch 12/18\n",
            "10/10 [==============================] - 5s 532ms/step - loss: 0.4792 - acc: 0.9390\n",
            " - 19s - loss: 0.2521 - acc: 0.8845 - val_loss: 0.4792 - val_acc: 0.9390\n",
            "Epoch 13/18\n",
            "10/10 [==============================] - 5s 535ms/step - loss: 0.3649 - acc: 0.9400\n",
            " - 19s - loss: 0.2445 - acc: 0.8960 - val_loss: 0.3649 - val_acc: 0.9400\n",
            "Epoch 14/18\n",
            "10/10 [==============================] - 5s 520ms/step - loss: 0.3149 - acc: 0.9570\n",
            " - 19s - loss: 0.2263 - acc: 0.9030 - val_loss: 0.3149 - val_acc: 0.9570\n",
            "Epoch 15/18\n",
            "10/10 [==============================] - 5s 547ms/step - loss: 0.2817 - acc: 0.9570\n",
            " - 19s - loss: 0.2799 - acc: 0.8845 - val_loss: 0.2817 - val_acc: 0.9570\n",
            "Epoch 16/18\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.3219 - acc: 0.9410\n",
            " - 19s - loss: 0.2864 - acc: 0.8720 - val_loss: 0.3219 - val_acc: 0.9410\n",
            "Epoch 17/18\n",
            "10/10 [==============================] - 5s 540ms/step - loss: 0.4533 - acc: 0.9330\n",
            " - 19s - loss: 0.2461 - acc: 0.8945 - val_loss: 0.4533 - val_acc: 0.9330\n",
            "Epoch 18/18\n",
            "10/10 [==============================] - 5s 549ms/step - loss: 0.3424 - acc: 0.9410\n",
            " - 20s - loss: 0.2406 - acc: 0.8955 - val_loss: 0.3424 - val_acc: 0.9410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "70d7b9d8-918a-4264-eaf0-846ea59cc33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wicQIveogBRV",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "63bd3c62-db1b-480f-bf12-ab5dcce27ae9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path='/content/' + fn\n",
        "  img=image.load_img(path, target_size=(150, 150))\n",
        "  \n",
        "  x=image.img_to_array(img)\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(classes[0])\n",
        "  \n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "    \n",
        "  else:\n",
        "    print(fn + \" is a cat\")\n",
        " "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-100118fc-5938-4841-88b8-07a741aa76ab\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-100118fc-5938-4841-88b8-07a741aa76ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dog_new.jpg to dog_new (6).jpg\n",
            "Saving dog_new2.jpeg to dog_new2 (5).jpeg\n",
            "Saving dog1.jpeg to dog1 (6).jpeg\n",
            "Saving dog2.jpg to dog2 (6).jpg\n",
            "Saving dog3.jpeg to dog3 (6).jpeg\n",
            "Saving dog4.jpg to dog4 (6).jpg\n",
            "[1.]\n",
            "dog1.jpeg is a dog\n",
            "[1.1510477e-19]\n",
            "dog3.jpeg is a cat\n",
            "[0.5967178]\n",
            "dog2.jpg is a dog\n",
            "[1.]\n",
            "dog4.jpg is a dog\n",
            "[1.2705242e-15]\n",
            "dog_new.jpg is a cat\n",
            "[1.]\n",
            "dog_new2.jpeg is a dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH2x5qjKgdqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}